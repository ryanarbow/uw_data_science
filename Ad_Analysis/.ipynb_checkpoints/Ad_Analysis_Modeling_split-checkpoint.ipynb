{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phases of data modeling - Test, train, deploy\n",
    "Classification model - where variable predicted (target) is categorical\n",
    "ad/nonad = binary classification\n",
    "classification model = \"classifier\"\n",
    "Data involved in classification models:\n",
    "inputs = features used in form of dataframe/matrix\n",
    "labels - column in dataframe\n",
    "entities after running classifier = predictive classes, and corresponding confidence\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our feature set we're going to create a binary classification model to make our ad/nonad prediction. \n",
    "\n",
    "First, we'll split the dataset into train and test sets. The split allows us to avoid overfitting the model. We'll follow the standard a 80% train /20% test data split.\n",
    "\n",
    "Next, we'll use the data to train and test three classifiers: Logistic Regression, Naive Bayes, and K Nearest Neighbor.\n",
    "\n",
    "Lastly, we'll evaluate these models using ROC curve and Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test\n",
    "\n",
    "To start, we will use pandas to import the feature set we previously created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read csv into a pandas dataframe\n",
    "ad_df = pd.read_csv('InternetAd_Dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will split the data into 1) labels - what we want to predict (in this case, ads) and 2) inputs (features) - the data used to predict the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign 'ad' column to y\n",
    "y = ad_df.ad\n",
    "\n",
    "#Create feature set which excludes the 'ad'\n",
    "X = ad_df.drop('ad', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To easily split the dataset into a training set and testing set, we'll import the train_test_split() function from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the train_test_split() function, we will pass the variables X and y that we obtained previously, along with test_size=0.20 which is used to indicate that the test data should be 20% of the total data and rest 80% should be train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, XX, Y, YY = train_test_split(X, y,test_size=0.2)\n",
    "#print(X_train)\n",
    "#print(X_train.head())\n",
    "# print(X_train.shape)\n",
    "# print(X_test)\n",
    "# print(X_test.head())\n",
    "# print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' CLASSIFICATION MODELS '"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" CLASSIFICATION MODELS \"\"\"\n",
    "# Logistic regression classifier\n",
    "# print ('\\n\\n\\nLogistic regression classifier\\n')\n",
    "# C_parameter = 50. / len(X) # parameter for regularization of the model\n",
    "# class_parameter = 'ovr' # parameter for dealing with multiple classes\n",
    "# penalty_parameter = 'l1' # parameter for the optimizer (solver) in the function\n",
    "# solver_parameter = 'saga' # optimization system used\n",
    "# tolerance_parameter = 0.1 # termination parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficients:\n",
      "[[-0.35454487  1.08159699 -0.3028099  ...  0.48153085  0.36702532\n",
      "  -0.08414805]]\n",
      "intercept:\n",
      "[-3.0447975]\n",
      "predictions for test set:\n",
      "[0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "actual class values:\n",
      "3117    0\n",
      "600     0\n",
      "2162    0\n",
      "2655    0\n",
      "2507    0\n",
      "1911    0\n",
      "1052    0\n",
      "1595    0\n",
      "3197    0\n",
      "167     1\n",
      "74      1\n",
      "2135    0\n",
      "2376    0\n",
      "389     1\n",
      "2038    0\n",
      "1286    0\n",
      "720     0\n",
      "803     0\n",
      "1738    0\n",
      "2723    0\n",
      "2599    0\n",
      "2736    0\n",
      "2465    0\n",
      "1012    0\n",
      "1341    0\n",
      "3063    0\n",
      "2932    0\n",
      "897     0\n",
      "1580    0\n",
      "1010    0\n",
      "       ..\n",
      "2424    0\n",
      "951     0\n",
      "791     0\n",
      "1661    0\n",
      "1900    0\n",
      "2484    0\n",
      "1068    0\n",
      "331     1\n",
      "1994    0\n",
      "2246    0\n",
      "242     1\n",
      "2305    0\n",
      "1318    0\n",
      "2284    0\n",
      "1459    0\n",
      "2496    0\n",
      "64      1\n",
      "1590    0\n",
      "825     0\n",
      "2761    0\n",
      "3102    0\n",
      "1405    0\n",
      "642     0\n",
      "3058    0\n",
      "1565    0\n",
      "2695    0\n",
      "2409    0\n",
      "1921    0\n",
      "2067    0\n",
      "255     1\n",
      "Name: ad, Length: 656, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Training the Model\n",
    "clf = LogisticRegression()#C=C_parameter, multi_class=class_parameter, penalty=penalty_parameter, solver=solver_parameter, tol=tolerance_parameter)\n",
    "clf.fit(X, Y) \n",
    "print ('coefficients:')\n",
    "print (clf.coef_) # each row of this matrix corresponds to each one of the classes of the dataset\n",
    "print ('intercept:')\n",
    "print (clf.intercept_) # each element of this vector corresponds to each one of the classes of the dataset\n",
    "\n",
    "#coefficient = importance\n",
    "# Apply the Model\n",
    "print ('predictions for test set:')\n",
    "print (clf.predict(XX))\n",
    "print ('actual class values:')\n",
    "print (YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Naive Bayes classifier\n",
      "\n",
      "predictions for test set:\n",
      "[0 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1\n",
      " 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 1\n",
      " 1 1 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0\n",
      " 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1\n",
      " 0 1 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0\n",
      " 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1\n",
      " 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1]\n",
      "actual class values:\n",
      "3117    0\n",
      "600     0\n",
      "2162    0\n",
      "2655    0\n",
      "2507    0\n",
      "1911    0\n",
      "1052    0\n",
      "1595    0\n",
      "3197    0\n",
      "167     1\n",
      "74      1\n",
      "2135    0\n",
      "2376    0\n",
      "389     1\n",
      "2038    0\n",
      "1286    0\n",
      "720     0\n",
      "803     0\n",
      "1738    0\n",
      "2723    0\n",
      "2599    0\n",
      "2736    0\n",
      "2465    0\n",
      "1012    0\n",
      "1341    0\n",
      "3063    0\n",
      "2932    0\n",
      "897     0\n",
      "1580    0\n",
      "1010    0\n",
      "       ..\n",
      "2424    0\n",
      "951     0\n",
      "791     0\n",
      "1661    0\n",
      "1900    0\n",
      "2484    0\n",
      "1068    0\n",
      "331     1\n",
      "1994    0\n",
      "2246    0\n",
      "242     1\n",
      "2305    0\n",
      "1318    0\n",
      "2284    0\n",
      "1459    0\n",
      "2496    0\n",
      "64      1\n",
      "1590    0\n",
      "825     0\n",
      "2761    0\n",
      "3102    0\n",
      "1405    0\n",
      "642     0\n",
      "3058    0\n",
      "1565    0\n",
      "2695    0\n",
      "2409    0\n",
      "1921    0\n",
      "2067    0\n",
      "255     1\n",
      "Name: ad, Length: 656, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes classifier\n",
    "print ('\\n\\nNaive Bayes classifier\\n')\n",
    "nbc = GaussianNB() # default parameters are fine\n",
    "nbc.fit(X, Y)\n",
    "print (\"predictions for test set:\")\n",
    "print (nbc.predict(XX))\n",
    "print ('actual class values:')\n",
    "print (YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "K nearest neighbors classifier\n",
      "\n",
      "predictions for test set:\n",
      "[0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "actual class values:\n",
      "1813    0\n",
      "2888    0\n",
      "765     0\n",
      "2271    0\n",
      "93      1\n",
      "355     1\n",
      "1697    0\n",
      "1686    0\n",
      "2398    0\n",
      "1141    0\n",
      "2860    0\n",
      "1069    0\n",
      "328     1\n",
      "3214    0\n",
      "341     1\n",
      "817     0\n",
      "269     1\n",
      "2047    0\n",
      "1636    0\n",
      "1306    0\n",
      "2217    0\n",
      "1274    0\n",
      "375     1\n",
      "1800    0\n",
      "1101    0\n",
      "1226    0\n",
      "900     0\n",
      "2605    0\n",
      "1979    0\n",
      "2998    0\n",
      "       ..\n",
      "165     1\n",
      "472     0\n",
      "2269    0\n",
      "1748    0\n",
      "639     0\n",
      "2719    0\n",
      "2442    0\n",
      "1368    0\n",
      "584     0\n",
      "143     1\n",
      "719     0\n",
      "2347    0\n",
      "2191    0\n",
      "3147    0\n",
      "1140    0\n",
      "2467    0\n",
      "1322    0\n",
      "2838    0\n",
      "1975    0\n",
      "1768    0\n",
      "103     1\n",
      "3240    0\n",
      "2679    0\n",
      "1693    0\n",
      "1856    0\n",
      "1341    0\n",
      "945     0\n",
      "3209    0\n",
      "2257    0\n",
      "188     1\n",
      "Name: ad, Length: 656, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# k Nearest Neighbors classifier\n",
    "print ('\\n\\nK nearest neighbors classifier\\n')\n",
    "k = 5 # number of neighbors\n",
    "distance_metric = 'euclidean'\n",
    "knn = KNeighborsClassifier(n_neighbors=k, metric=distance_metric)\n",
    "knn.fit(X, Y)\n",
    "print (\"predictions for test set:\")\n",
    "print (knn.predict(XX))\n",
    "print ('actual class values:')\n",
    "print (YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
