{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Milestone 3 - Instructions\n",
    "Create a new notebook and perform each of the following tasks and answer the related questions:\n",
    "\n",
    "- Build a simple neural networks model\n",
    "- Build a DNN model\n",
    "- Build a RNN model\n",
    "- Summarize your findings with examples.  Explain what the manufacturer should focus on to optimize the diaper manufacturing process.\n",
    "- Solicit specific feedback on your code (instructions below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign url variable where we will pull data from\n",
    "url_data = \"https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add generic feature column names\n",
    "names = [\"feature\" + str(x) for x in range(1, 591)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull down the csv info into a pandas dataframe\n",
    "data = pd.read_csv(url_data, sep=\" \", names=names, header=None, dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature581</th>\n",
       "      <th>feature582</th>\n",
       "      <th>feature583</th>\n",
       "      <th>feature584</th>\n",
       "      <th>feature585</th>\n",
       "      <th>feature586</th>\n",
       "      <th>feature587</th>\n",
       "      <th>feature588</th>\n",
       "      <th>feature589</th>\n",
       "      <th>feature590</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2   feature3   feature4  feature5  feature6  feature7  \\\n",
       "0   3030.93   2564.00  2187.7333  1411.1265    1.3602     100.0   97.6133   \n",
       "1   3095.78   2465.14  2230.4222  1463.6606    0.8294     100.0  102.3433   \n",
       "2   2932.61   2559.94  2186.4111  1698.0172    1.5102     100.0   95.4878   \n",
       "3   2988.72   2479.90  2199.0333   909.7926    1.3204     100.0  104.2367   \n",
       "4   3032.24   2502.87  2233.3667  1326.5200    1.5334     100.0  100.3967   \n",
       "\n",
       "   feature8  feature9  feature10  ...  feature581  feature582  feature583  \\\n",
       "0    0.1242    1.5005     0.0162  ...         NaN         NaN      0.5005   \n",
       "1    0.1247    1.4966    -0.0005  ...      0.0060    208.2045      0.5019   \n",
       "2    0.1241    1.4436     0.0041  ...      0.0148     82.8602      0.4958   \n",
       "3    0.1217    1.4882    -0.0124  ...      0.0044     73.8432      0.4990   \n",
       "4    0.1235    1.5031    -0.0031  ...         NaN         NaN      0.4800   \n",
       "\n",
       "   feature584  feature585  feature586  feature587  feature588  feature589  \\\n",
       "0      0.0118      0.0035      2.3630         NaN         NaN         NaN   \n",
       "1      0.0223      0.0055      4.4447      0.0096      0.0201      0.0060   \n",
       "2      0.0157      0.0039      3.1745      0.0584      0.0484      0.0148   \n",
       "3      0.0103      0.0025      2.0544      0.0202      0.0149      0.0044   \n",
       "4      0.4766      0.1045     99.3032      0.0202      0.0149      0.0044   \n",
       "\n",
       "   feature590  \n",
       "0         NaN  \n",
       "1    208.2045  \n",
       "2     82.8602  \n",
       "3     73.8432  \n",
       "4     73.8432  \n",
       "\n",
       "[5 rows x 590 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check head of data \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign url variable where we will pull classification data from\n",
    "url_classifications = \"https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom_labels.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign classification and date to labels\n",
    "labels = pd.read_csv(url_classifications, sep=\" \", names = [\"classification\",\"date\"],parse_dates = [\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data with classification labels\n",
    "df = pd.concat([data,labels], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to dataset information this data contains null values varying in intensity depending on the individuals features. \n",
    "\n",
    "The data is represented in a raw text file each line representing an individual example and the features seperated by spaces. The null values are represented by the 'NaN' value as per MatLab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace missing values with median values\n",
    "df.fillna(data.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1          0\n",
      "feature2          0\n",
      "feature3          0\n",
      "feature4          0\n",
      "feature5          0\n",
      "                 ..\n",
      "feature588        0\n",
      "feature589        0\n",
      "feature590        0\n",
      "classification    0\n",
      "date              0\n",
      "Length: 592, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the date column\n",
    "df = df.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all columns with 0 std \n",
    "df = df.loc[:, df.std() > .0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10da7f898>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['classification'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle class imbalance problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define predicators and target\n",
    "\n",
    "X = All features minus the target, column \"classification\"\n",
    "\n",
    "y = classification - simple pass/fail yield for in house line testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X \n",
    "X = df.drop('classification', axis=1)\n",
    "\n",
    "# define y\n",
    "y = df['classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({-1: 1463, 1: 1463})\n"
     ]
    }
   ],
   "source": [
    "# use SMOTE to resample data from X, y\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_sample(X, y)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine resampled x and y into new dataframe\n",
    "resampled = pd.DataFrame(X_res, columns=X.columns)\n",
    "\n",
    "resampled['classification'] = y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature582</th>\n",
       "      <th>feature583</th>\n",
       "      <th>feature584</th>\n",
       "      <th>feature585</th>\n",
       "      <th>feature586</th>\n",
       "      <th>feature587</th>\n",
       "      <th>feature588</th>\n",
       "      <th>feature589</th>\n",
       "      <th>feature590</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>...</td>\n",
       "      <td>72.2889</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>71.9005</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0148</td>\n",
       "      <td>...</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>...</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>...</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>...</td>\n",
       "      <td>72.2889</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 475 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2   feature3   feature4  feature5  feature7  feature8  \\\n",
       "0   3030.93   2564.00  2187.7333  1411.1265    1.3602   97.6133    0.1242   \n",
       "1   3095.78   2465.14  2230.4222  1463.6606    0.8294  102.3433    0.1247   \n",
       "2   2932.61   2559.94  2186.4111  1698.0172    1.5102   95.4878    0.1241   \n",
       "3   2988.72   2479.90  2199.0333   909.7926    1.3204  104.2367    0.1217   \n",
       "4   3032.24   2502.87  2233.3667  1326.5200    1.5334  100.3967    0.1235   \n",
       "\n",
       "   feature9  feature10  feature11  ...  feature582  feature583  feature584  \\\n",
       "0    1.5005     0.0162    -0.0034  ...     72.2889      0.5005      0.0118   \n",
       "1    1.4966    -0.0005    -0.0148  ...    208.2045      0.5019      0.0223   \n",
       "2    1.4436     0.0041     0.0013  ...     82.8602      0.4958      0.0157   \n",
       "3    1.4882    -0.0124    -0.0033  ...     73.8432      0.4990      0.0103   \n",
       "4    1.5031    -0.0031    -0.0072  ...     72.2889      0.4800      0.4766   \n",
       "\n",
       "   feature585  feature586  feature587  feature588  feature589  feature590  \\\n",
       "0      0.0035      2.3630      0.0205      0.0148      0.0046     71.9005   \n",
       "1      0.0055      4.4447      0.0096      0.0201      0.0060    208.2045   \n",
       "2      0.0039      3.1745      0.0584      0.0484      0.0148     82.8602   \n",
       "3      0.0025      2.0544      0.0202      0.0149      0.0044     73.8432   \n",
       "4      0.1045     99.3032      0.0202      0.0149      0.0044     73.8432   \n",
       "\n",
       "   classification  \n",
       "0              -1  \n",
       "1              -1  \n",
       "2               1  \n",
       "3              -1  \n",
       "4              -1  \n",
       "\n",
       "[5 rows x 475 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine X \n",
    "X = resampled.drop('classification', axis=1)\n",
    "\n",
    "# redefine y\n",
    "Y = resampled['classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into a training and testing set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a simple neural networks model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = Y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = Y1.reshape((Y1.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a numerically stable logistic s-shaped definition to call\n",
    "def sigmoid(x):\n",
    "    x = np.clip(x, -500, 500)\n",
    "    if x.any()>=0:\n",
    "        return 1/(1 + np.exp(-x))\n",
    "    else:\n",
    "        return np.exp(x)/(1 + np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dimentions and set the weights to random numbers\n",
    "def init_parameters(dim1, dim2=1,std=1e-1, random = True):\n",
    "    if(random):\n",
    "        return(np.random.random([dim1,dim2])*std)\n",
    "    else:\n",
    "        return(np.zeros([dim1,dim2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single layer network: Forward Prop\n",
    "# Passed in the weight vectors, bias vector, the input vector and the Y\n",
    "def fwd_prop(W1,bias,X,Y1):\n",
    "\n",
    "    Z1 = np.dot(W1,X) + bias # dot product of the weights and X + bias\n",
    "    A1 = sigmoid(Z1)  # Uses sigmoid to create a predicted vector\n",
    "\n",
    "    return(A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single layer network: Backprop\n",
    "\n",
    "def back_prop(A1,W1,bias,X,Y1):\n",
    "\n",
    "    m = np.shape(X)[1] # used the calculate the cost by the number of inputs -1/m\n",
    "   \n",
    "    # Cross entropy loss function\n",
    "    cost = (-1/m)*np.sum(Y1*np.log(A1) + (1-Y1)*np.log(1-A1)) # cost of error\n",
    "    dZ1 = A1 - Y1                                            # subtract actual from pred weights\n",
    "    dW1 = (1/m) * np.dot(dZ1, X.T)                          # calc new weight vector\n",
    "    dBias = (1/m) * np.sum(dZ1, axis = 1, keepdims = True)  # calc new bias vector\n",
    "    \n",
    "    grads ={\"dW1\": dW1, \"dB1\":dBias} # Weight and bias vectors after backprop\n",
    "    \n",
    "    return(grads,cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grad_desc(num_epochs,learning_rate,X,Y1,n_1):\n",
    "    \n",
    "    n_0, m = np.shape(X)\n",
    "    \n",
    "    W1 = init_parameters(n_1, n_0, True)\n",
    "    B1 = init_parameters(n_1,1, True)\n",
    "    \n",
    "    loss_array = np.ones([num_epochs])*np.nan # resets the loss_array to NaNs\n",
    "    \n",
    "    for i in np.arange(num_epochs):\n",
    "        A1 = fwd_prop(W1,B1,X,Y1)                # get predicted vector\n",
    "        grads,cost = back_prop(A1,W1,B1,X,Y1)    # get gradient and the cost from BP \n",
    "        \n",
    "        W1 = W1 - learning_rate*grads[\"dW1\"]    # update weight vector LR*gradient*[BP weights]\n",
    "        B1 = B1 - learning_rate*grads[\"dB1\"]    # update bias LR*gradient[BP bias]\n",
    "        \n",
    "        loss_array[i] = cost                    # loss array gets cross ent values\n",
    "        \n",
    "        parameter = {\"W1\":W1,\"B1\":B1}           # assign \n",
    "    \n",
    "    return(parameter,loss_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in multiply\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "learning_rate = 0.000001\n",
    "params, loss_array = run_grad_desc(num_epochs,learning_rate,X,Y1,n_1= 1 )\n",
    "print(loss_array[num_epochs-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a DNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=474))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compilation - configure the learning process including defining the optimizer, loss function, and metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model  with our training data and by defining the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2340/2340 [==============================] - 0s 101us/step - loss: -0.0138 - acc: 0.0017\n",
      "Epoch 2/5\n",
      "2340/2340 [==============================] - 0s 34us/step - loss: -0.0138 - acc: 0.0017\n",
      "Epoch 3/5\n",
      "2340/2340 [==============================] - 0s 33us/step - loss: -0.0138 - acc: 0.0017\n",
      "Epoch 4/5\n",
      "2340/2340 [==============================] - 0s 35us/step - loss: -0.0138 - acc: 0.0017\n",
      "Epoch 5/5\n",
      "2340/2340 [==============================] - 0s 52us/step - loss: -0.0138 - acc: 0.0017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13ce09630>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply model to test set and evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586/586 [==============================] - 0s 17us/step\n",
      "Test accuracy: 0.0017064846416382253\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions to Solicit Feedback\n",
    "Write 2-3 questions soliciting feedback on specific aspects on the assignment. For example, if you did something one way but are unsure if there might be a different or better way to do it, ask for feedback on that part. You may submit these questions by commenting out in the code within your .ipynb file or by typing them below your file name in the Your Response box on the Submit Milestone Assignment page. While the questions you submit will have no bearing on your grade, by doing so, you will engage more actively with the assignment and we will also be able to give you pointed feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How can I fix the convegence issue I have with svm.LinearSVC? From what I've found on Stackoverflow, the common response is to increase the iterations. I went from 1000 to 100000; however, still received this error. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. I did not find a difference in performace (accuracy) using thw whole dataset vs. a limited dataset (after dimensionality reduction) when using Decision Tree or Random Forest. Is that normal? If not, how and when should I use dimensionality reduction for these models moving forward? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
