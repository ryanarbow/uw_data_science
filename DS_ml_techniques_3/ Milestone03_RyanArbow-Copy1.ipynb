{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Milestone 3 - Instructions\n",
    "Create a new notebook and perform each of the following tasks and answer the related questions:\n",
    "\n",
    "- Build a simple neural networks model\n",
    "- Build a DNN model\n",
    "- Build a RNN model\n",
    "- Summarize your findings with examples.  Explain what the manufacturer should focus on to optimize the diaper manufacturing process.\n",
    "- Solicit specific feedback on your code (instructions below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Dropout, Dense, Embedding, LSTM, Bidirectional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign url variable where we will pull data from\n",
    "url_data = \"https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add generic feature column names\n",
    "names = [\"feature\" + str(x) for x in range(1, 591)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull down the csv info into a pandas dataframe\n",
    "data = pd.read_csv(url_data, sep=\" \", names=names, header=None, dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature581</th>\n",
       "      <th>feature582</th>\n",
       "      <th>feature583</th>\n",
       "      <th>feature584</th>\n",
       "      <th>feature585</th>\n",
       "      <th>feature586</th>\n",
       "      <th>feature587</th>\n",
       "      <th>feature588</th>\n",
       "      <th>feature589</th>\n",
       "      <th>feature590</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2   feature3   feature4  feature5  feature6  feature7  \\\n",
       "0   3030.93   2564.00  2187.7333  1411.1265    1.3602     100.0   97.6133   \n",
       "1   3095.78   2465.14  2230.4222  1463.6606    0.8294     100.0  102.3433   \n",
       "2   2932.61   2559.94  2186.4111  1698.0172    1.5102     100.0   95.4878   \n",
       "3   2988.72   2479.90  2199.0333   909.7926    1.3204     100.0  104.2367   \n",
       "4   3032.24   2502.87  2233.3667  1326.5200    1.5334     100.0  100.3967   \n",
       "\n",
       "   feature8  feature9  feature10  ...  feature581  feature582  feature583  \\\n",
       "0    0.1242    1.5005     0.0162  ...         NaN         NaN      0.5005   \n",
       "1    0.1247    1.4966    -0.0005  ...      0.0060    208.2045      0.5019   \n",
       "2    0.1241    1.4436     0.0041  ...      0.0148     82.8602      0.4958   \n",
       "3    0.1217    1.4882    -0.0124  ...      0.0044     73.8432      0.4990   \n",
       "4    0.1235    1.5031    -0.0031  ...         NaN         NaN      0.4800   \n",
       "\n",
       "   feature584  feature585  feature586  feature587  feature588  feature589  \\\n",
       "0      0.0118      0.0035      2.3630         NaN         NaN         NaN   \n",
       "1      0.0223      0.0055      4.4447      0.0096      0.0201      0.0060   \n",
       "2      0.0157      0.0039      3.1745      0.0584      0.0484      0.0148   \n",
       "3      0.0103      0.0025      2.0544      0.0202      0.0149      0.0044   \n",
       "4      0.4766      0.1045     99.3032      0.0202      0.0149      0.0044   \n",
       "\n",
       "   feature590  \n",
       "0         NaN  \n",
       "1    208.2045  \n",
       "2     82.8602  \n",
       "3     73.8432  \n",
       "4     73.8432  \n",
       "\n",
       "[5 rows x 590 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check head of data \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign url variable where we will pull classification data from\n",
    "url_classifications = \"https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom_labels.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign classification and date to labels\n",
    "labels = pd.read_csv(url_classifications, sep=\" \", names = [\"classification\",\"date\"],parse_dates = [\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data with classification labels\n",
    "df = pd.concat([data,labels], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to dataset information this data contains null values varying in intensity depending on the individuals features. \n",
    "\n",
    "The data is represented in a raw text file each line representing an individual example and the features seperated by spaces. The null values are represented by the 'NaN' value as per MatLab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace missing values with median values\n",
    "df.fillna(data.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1          0\n",
      "feature2          0\n",
      "feature3          0\n",
      "feature4          0\n",
      "feature5          0\n",
      "                 ..\n",
      "feature588        0\n",
      "feature589        0\n",
      "feature590        0\n",
      "classification    0\n",
      "date              0\n",
      "Length: 592, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the date column\n",
    "df = df.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all columns with 0 std \n",
    "df = df.loc[:, df.std() > .0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13f29b828>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAO90lEQVR4nO3df6zdd13H8efL1g2BSLv1WmbbeRtpMJNoaG7GDIkh1GzdMHR/ANliXJ01jXEoOhIo+EcTCGYE42QJLims0iVksEx0DUxnMyDE6ObuBoz9AHcz2NpmWy+0zB8LYvXtH/czPdzd29t7z+25Wz/PR3Jyvt/35/P9ft8nuXmdbz7nnDZVhSSpDz+x0g1IkkbH0Jekjhj6ktQRQ1+SOmLoS1JHVq90A6eybt26Gh8fX+k2JOll5YEHHvheVY3NNfaSDv3x8XEmJydXug1JellJ8uR8Yy7vSFJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSR17Sv8h9uRjf88WVbuGs8t0b3rbSLUhnLe/0Jakjhr4kdcTQl6SOGPqS1JEFQz/J/iTHkjw8x9h7k1SSdW0/SW5KMpXkoSRbB+buTPJ4e+xc3pchSTodp3On/2lg++xikk3ApcBTA+XLgS3tsRu4uc09D9gLvAm4GNibZO0wjUuSFm/B0K+qrwLH5xi6EXgfUAO1HcCtNeNeYE2SC4DLgENVdbyqTgCHmOONRJJ0Zi1pTT/JDuBoVX1j1tAG4PDA/pFWm68uSRqhRf84K8krgQ8ys7Sz7JLsZmZpiAsvvPBMXEKSurWUO/2fBzYD30jyXWAj8GCS1wJHgU0Dcze22nz1F6mqfVU1UVUTY2Nz/r++kqQlWnToV9U3q+pnqmq8qsaZWarZWlXPAAeBa9q3eC4Bnquqp4G7gUuTrG0f4F7aapKkETqdr2zeBvwT8PokR5LsOsX0u4AngCngk8DvAVTVceDDwP3t8aFWkySN0IJr+lV19QLj4wPbBVw3z7z9wP5F9idJWkb+IleSOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR1ZMPST7E9yLMnDA7WPJflWkoeS/HWSNQNjH0gyleTbSS4bqG9vtakke5b/pUiSFnI6d/qfBrbPqh0C3lBVvwT8C/ABgCQXAVcBv9iO+Yskq5KsAj4BXA5cBFzd5kqSRmjB0K+qrwLHZ9X+vqpOtt17gY1tewfw2ar6z6r6DjAFXNweU1X1RFX9CPhsmytJGqHlWNP/beBv2/YG4PDA2JFWm6/+Ikl2J5lMMjk9Pb0M7UmSXjBU6Cf5Y+Ak8JnlaQeqal9VTVTVxNjY2HKdVpIErF7qgUl+C/h1YFtVVSsfBTYNTNvYapyiLkkakSXd6SfZDrwPeHtVPT8wdBC4Ksm5STYDW4B/Bu4HtiTZnOQcZj7sPThc65KkxVrwTj/JbcBbgHVJjgB7mfm2zrnAoSQA91bV71bVI0luBx5lZtnnuqr673aedwN3A6uA/VX1yBl4PZKkU1gw9Kvq6jnKt5xi/keAj8xRvwu4a1HdSZKWlb/IlaSOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjqyYOgn2Z/kWJKHB2rnJTmU5PH2vLbVk+SmJFNJHkqydeCYnW3+40l2npmXI0k6ldO50/80sH1WbQ9wT1VtAe5p+wCXA1vaYzdwM8y8SQB7gTcBFwN7X3ijkCSNzoKhX1VfBY7PKu8ADrTtA8CVA/Vba8a9wJokFwCXAYeq6nhVnQAO8eI3EknSGbbUNf31VfV0234GWN+2NwCHB+YdabX56i+SZHeSySST09PTS2xPkjSXoT/IraoCahl6eeF8+6pqoqomxsbGluu0kiSWHvrPtmUb2vOxVj8KbBqYt7HV5qtLkkZoqaF/EHjhGzg7gTsH6te0b/FcAjzXloHuBi5NsrZ9gHtpq0mSRmj1QhOS3Aa8BViX5Agz38K5Abg9yS7gSeBdbfpdwBXAFPA8cC1AVR1P8mHg/jbvQ1U1+8NhSdIZtmDoV9XV8wxtm2NuAdfNc579wP5FdSdJWlb+IleSOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyFChn+SPkjyS5OEktyV5RZLNSe5LMpXkc0nOaXPPbftTbXx8OV6AJOn0LTn0k2wA/gCYqKo3AKuAq4CPAjdW1euAE8Cudsgu4ESr39jmSZJGaNjlndXATyVZDbwSeBp4K3BHGz8AXNm2d7R92vi2JBny+pKkRVhy6FfVUeBPgaeYCfvngAeAH1TVyTbtCLChbW8ADrdjT7b55y/1+pKkxRtmeWctM3fvm4GfBV4FbB+2oSS7k0wmmZyenh72dJKkAcMs7/wa8J2qmq6q/wI+D7wZWNOWewA2Akfb9lFgE0Abfw3w/dknrap9VTVRVRNjY2NDtCdJmm2Y0H8KuCTJK9va/DbgUeDLwDvanJ3AnW37YNunjX+pqmqI60uSFmmYNf37mPlA9kHgm+1c+4D3A9cnmWJmzf6WdsgtwPmtfj2wZ4i+JUlLsHrhKfOrqr3A3lnlJ4CL55j7Q+Cdw1xPkjQcf5ErSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SODBX6SdYkuSPJt5I8luRXkpyX5FCSx9vz2jY3SW5KMpXkoSRbl+clSJJO17B3+h8H/q6qfgH4ZeAxYA9wT1VtAe5p+wCXA1vaYzdw85DXliQt0pJDP8lrgF8FbgGoqh9V1Q+AHcCBNu0AcGXb3gHcWjPuBdYkuWDJnUuSFm2YO/3NwDTwl0m+luRTSV4FrK+qp9ucZ4D1bXsDcHjg+COt9mOS7E4ymWRyenp6iPYkSbMNE/qrga3AzVX1RuA/+P+lHACqqoBazEmral9VTVTVxNjY2BDtSZJmGyb0jwBHquq+tn8HM28Cz76wbNOej7Xxo8CmgeM3tpokaUSWHPpV9QxwOMnrW2kb8ChwENjZajuBO9v2QeCa9i2eS4DnBpaBJEkjsHrI438f+EySc4AngGuZeSO5Pcku4EngXW3uXcAVwBTwfJsrSRqhoUK/qr4OTMwxtG2OuQVcN8z1JEnD8Re5ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkeGDv0kq5J8LckX2v7mJPclmUryufafppPk3LY/1cbHh722JGlxluNO/z3AYwP7HwVurKrXASeAXa2+CzjR6je2eZKkERoq9JNsBN4GfKrtB3grcEebcgC4sm3vaPu08W1tviRpRIa90/9z4H3A/7T984EfVNXJtn8E2NC2NwCHAdr4c23+j0myO8lkksnp6ekh25MkDVpy6Cf5deBYVT2wjP1QVfuqaqKqJsbGxpbz1JLUvdVDHPtm4O1JrgBeAfw08HFgTZLV7W5+I3C0zT8KbAKOJFkNvAb4/hDXlyQt0pLv9KvqA1W1sarGgauAL1XVbwBfBt7Rpu0E7mzbB9s+bfxLVVVLvb4kafHOxPf03w9cn2SKmTX7W1r9FuD8Vr8e2HMGri1JOoVhlnf+T1V9BfhK234CuHiOOT8E3rkc15MkLY2/yJWkjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6suTQT7IpyZeTPJrkkSTvafXzkhxK8nh7XtvqSXJTkqkkDyXZulwvQpJ0eoa50z8JvLeqLgIuAa5LchGwB7inqrYA97R9gMuBLe2xG7h5iGtLkpZgyaFfVU9X1YNt+9+Ax4ANwA7gQJt2ALiybe8Abq0Z9wJrklyw5M4lSYu2LGv6ScaBNwL3Aeur6uk29Aywvm1vAA4PHHak1Wafa3eSySST09PTy9GeJKkZOvSTvBr4K+APq+pfB8eqqoBazPmqal9VTVTVxNjY2LDtSZIGDBX6SX6SmcD/TFV9vpWffWHZpj0fa/WjwKaBwze2miRpRIb59k6AW4DHqurPBoYOAjvb9k7gzoH6Ne1bPJcAzw0sA0mSRmD1EMe+GfhN4JtJvt5qHwRuAG5Psgt4EnhXG7sLuAKYAp4Hrh3i2pKkJVhy6FfVPwCZZ3jbHPMLuG6p15MkDc9f5EpSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6MswvciW9DIzv+eJKt3DW+O4Nb1vpFobmnb4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktSRkYd+ku1Jvp1kKsmeUV9fkno20tBPsgr4BHA5cBFwdZKLRtmDJPVs1Hf6FwNTVfVEVf0I+CywY8Q9SFK3Rv1PK28ADg/sHwHeNDghyW5gd9v99yTfHlFvPVgHfG+lm1hIPrrSHWiFvOT/Pl9Gf5s/N9/AS+7f06+qfcC+le7jbJRksqomVroPaS7+fY7GqJd3jgKbBvY3tpokaQRGHfr3A1uSbE5yDnAVcHDEPUhSt0a6vFNVJ5O8G7gbWAXsr6pHRtlD51w200uZf58jkKpa6R4kSSPiL3IlqSOGviR1xNCXpI4Y+pLUEUO/Q0levdI9SPNJcu1K93A289s7HUryVFVduNJ9SHPx7/PMesn9MwxaHkmun28I8E5fKyrJQ/MNAetH2UtvDP2z158AHwNOzjHmsp5W2nrgMuDErHqAfxx9O/0w9M9eDwJ/U1UPzB5I8jsr0I806AvAq6vq67MHknxl9O30wzX9s1SS1wPfr6rvDdReW1XPJFlfVc+uYHuSVoih35EkD1bV1pXuQ9LKcW23L1npBiStLEO/L59c6QYkrSyXdySpI97pS1JHDH1J6oihL0kdMfQlqSP/C0dmueCIm9RQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['classification'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle class imbalance problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define predicators and target\n",
    "\n",
    "X = All features minus the target, column \"classification\"\n",
    "\n",
    "y = classification - simple pass/fail yield for in house line testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X \n",
    "X = df.drop('classification', axis=1)\n",
    "\n",
    "# define y\n",
    "y = df['classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({-1: 1463, 1: 1463})\n"
     ]
    }
   ],
   "source": [
    "# use SMOTE to resample data from X, y\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_sample(X, y)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine resampled x and y into new dataframe\n",
    "resampled = pd.DataFrame(X_res, columns=X.columns)\n",
    "\n",
    "resampled['classification'] = y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature582</th>\n",
       "      <th>feature583</th>\n",
       "      <th>feature584</th>\n",
       "      <th>feature585</th>\n",
       "      <th>feature586</th>\n",
       "      <th>feature587</th>\n",
       "      <th>feature588</th>\n",
       "      <th>feature589</th>\n",
       "      <th>feature590</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>...</td>\n",
       "      <td>72.2889</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>71.9005</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0148</td>\n",
       "      <td>...</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>...</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>...</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>...</td>\n",
       "      <td>72.2889</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 475 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2   feature3   feature4  feature5  feature7  feature8  \\\n",
       "0   3030.93   2564.00  2187.7333  1411.1265    1.3602   97.6133    0.1242   \n",
       "1   3095.78   2465.14  2230.4222  1463.6606    0.8294  102.3433    0.1247   \n",
       "2   2932.61   2559.94  2186.4111  1698.0172    1.5102   95.4878    0.1241   \n",
       "3   2988.72   2479.90  2199.0333   909.7926    1.3204  104.2367    0.1217   \n",
       "4   3032.24   2502.87  2233.3667  1326.5200    1.5334  100.3967    0.1235   \n",
       "\n",
       "   feature9  feature10  feature11  ...  feature582  feature583  feature584  \\\n",
       "0    1.5005     0.0162    -0.0034  ...     72.2889      0.5005      0.0118   \n",
       "1    1.4966    -0.0005    -0.0148  ...    208.2045      0.5019      0.0223   \n",
       "2    1.4436     0.0041     0.0013  ...     82.8602      0.4958      0.0157   \n",
       "3    1.4882    -0.0124    -0.0033  ...     73.8432      0.4990      0.0103   \n",
       "4    1.5031    -0.0031    -0.0072  ...     72.2889      0.4800      0.4766   \n",
       "\n",
       "   feature585  feature586  feature587  feature588  feature589  feature590  \\\n",
       "0      0.0035      2.3630      0.0205      0.0148      0.0046     71.9005   \n",
       "1      0.0055      4.4447      0.0096      0.0201      0.0060    208.2045   \n",
       "2      0.0039      3.1745      0.0584      0.0484      0.0148     82.8602   \n",
       "3      0.0025      2.0544      0.0202      0.0149      0.0044     73.8432   \n",
       "4      0.1045     99.3032      0.0202      0.0149      0.0044     73.8432   \n",
       "\n",
       "   classification  \n",
       "0              -1  \n",
       "1              -1  \n",
       "2               1  \n",
       "3              -1  \n",
       "4              -1  \n",
       "\n",
       "[5 rows x 475 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine X \n",
    "X = resampled.drop('classification', axis=1)\n",
    "\n",
    "# redefine y\n",
    "Y = resampled['classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into a training and testing set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a simple neural networks model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature581</th>\n",
       "      <th>feature582</th>\n",
       "      <th>feature583</th>\n",
       "      <th>feature584</th>\n",
       "      <th>feature585</th>\n",
       "      <th>feature586</th>\n",
       "      <th>feature587</th>\n",
       "      <th>feature588</th>\n",
       "      <th>feature589</th>\n",
       "      <th>feature590</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>3065.590357</td>\n",
       "      <td>2554.018010</td>\n",
       "      <td>2239.066660</td>\n",
       "      <td>1459.259069</td>\n",
       "      <td>1.756294</td>\n",
       "      <td>102.077025</td>\n",
       "      <td>0.119660</td>\n",
       "      <td>1.438020</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>0.006540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>72.288900</td>\n",
       "      <td>0.503040</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>2.085128</td>\n",
       "      <td>0.026650</td>\n",
       "      <td>0.013950</td>\n",
       "      <td>0.004570</td>\n",
       "      <td>52.572526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>3102.590000</td>\n",
       "      <td>2514.950000</td>\n",
       "      <td>2196.088900</td>\n",
       "      <td>1277.859200</td>\n",
       "      <td>1.824600</td>\n",
       "      <td>95.632200</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>1.472700</td>\n",
       "      <td>-0.000500</td>\n",
       "      <td>-0.007600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>72.288900</td>\n",
       "      <td>0.500200</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>3.246600</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>16.669500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2938.410000</td>\n",
       "      <td>2466.780000</td>\n",
       "      <td>2166.522200</td>\n",
       "      <td>907.074600</td>\n",
       "      <td>1.064700</td>\n",
       "      <td>104.521100</td>\n",
       "      <td>0.122100</td>\n",
       "      <td>1.471000</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>50.871300</td>\n",
       "      <td>0.498700</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>2.135600</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>50.871300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>2977.935423</td>\n",
       "      <td>2373.440416</td>\n",
       "      <td>2171.779115</td>\n",
       "      <td>1151.744525</td>\n",
       "      <td>1.207409</td>\n",
       "      <td>101.097817</td>\n",
       "      <td>0.121995</td>\n",
       "      <td>1.549579</td>\n",
       "      <td>0.013609</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>58.474471</td>\n",
       "      <td>0.498650</td>\n",
       "      <td>0.009780</td>\n",
       "      <td>0.002580</td>\n",
       "      <td>1.958154</td>\n",
       "      <td>0.027196</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.003610</td>\n",
       "      <td>51.131419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>2956.527885</td>\n",
       "      <td>2536.652323</td>\n",
       "      <td>2183.191911</td>\n",
       "      <td>995.962387</td>\n",
       "      <td>1.348479</td>\n",
       "      <td>104.080694</td>\n",
       "      <td>0.122884</td>\n",
       "      <td>1.529538</td>\n",
       "      <td>-0.023359</td>\n",
       "      <td>-0.003883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007306</td>\n",
       "      <td>112.416712</td>\n",
       "      <td>0.494457</td>\n",
       "      <td>0.013775</td>\n",
       "      <td>0.003619</td>\n",
       "      <td>2.787776</td>\n",
       "      <td>0.026678</td>\n",
       "      <td>0.020775</td>\n",
       "      <td>0.007306</td>\n",
       "      <td>112.416712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>2988.832251</td>\n",
       "      <td>2518.943892</td>\n",
       "      <td>2227.941084</td>\n",
       "      <td>1380.972197</td>\n",
       "      <td>1.548322</td>\n",
       "      <td>107.313477</td>\n",
       "      <td>0.122713</td>\n",
       "      <td>1.464299</td>\n",
       "      <td>-0.004470</td>\n",
       "      <td>-0.011010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>72.288900</td>\n",
       "      <td>0.501250</td>\n",
       "      <td>0.012642</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>2.523518</td>\n",
       "      <td>0.029922</td>\n",
       "      <td>0.022965</td>\n",
       "      <td>0.006550</td>\n",
       "      <td>84.970087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>3077.470000</td>\n",
       "      <td>2387.730000</td>\n",
       "      <td>2180.888900</td>\n",
       "      <td>1084.722100</td>\n",
       "      <td>0.908500</td>\n",
       "      <td>94.246700</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>1.314500</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>-0.020900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>72.288900</td>\n",
       "      <td>0.497700</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>3.033000</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>51.472600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>3090.201242</td>\n",
       "      <td>2524.409307</td>\n",
       "      <td>2195.395247</td>\n",
       "      <td>1345.746906</td>\n",
       "      <td>1.112359</td>\n",
       "      <td>100.135905</td>\n",
       "      <td>0.123700</td>\n",
       "      <td>1.415041</td>\n",
       "      <td>-0.004198</td>\n",
       "      <td>-0.001794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>72.288900</td>\n",
       "      <td>0.501121</td>\n",
       "      <td>0.010838</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>2.161356</td>\n",
       "      <td>0.020761</td>\n",
       "      <td>0.008666</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>41.905874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>2904.618155</td>\n",
       "      <td>2475.227573</td>\n",
       "      <td>2172.937599</td>\n",
       "      <td>925.868956</td>\n",
       "      <td>1.047679</td>\n",
       "      <td>103.826351</td>\n",
       "      <td>0.121855</td>\n",
       "      <td>1.531818</td>\n",
       "      <td>-0.020960</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004765</td>\n",
       "      <td>99.013260</td>\n",
       "      <td>0.502779</td>\n",
       "      <td>0.013103</td>\n",
       "      <td>0.003080</td>\n",
       "      <td>2.602076</td>\n",
       "      <td>0.023556</td>\n",
       "      <td>0.013508</td>\n",
       "      <td>0.004206</td>\n",
       "      <td>81.909187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>2983.523282</td>\n",
       "      <td>2489.685582</td>\n",
       "      <td>2169.804637</td>\n",
       "      <td>1293.480283</td>\n",
       "      <td>0.982741</td>\n",
       "      <td>108.746110</td>\n",
       "      <td>0.124532</td>\n",
       "      <td>1.384817</td>\n",
       "      <td>0.006344</td>\n",
       "      <td>-0.002782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>70.958859</td>\n",
       "      <td>0.498551</td>\n",
       "      <td>0.016340</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>3.283800</td>\n",
       "      <td>0.030427</td>\n",
       "      <td>0.020020</td>\n",
       "      <td>0.007268</td>\n",
       "      <td>66.090988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2340 rows Ã— 474 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature1     feature2     feature3     feature4  feature5  \\\n",
       "1778  3065.590357  2554.018010  2239.066660  1459.259069  1.756294   \n",
       "441   3102.590000  2514.950000  2196.088900  1277.859200  1.824600   \n",
       "52    2938.410000  2466.780000  2166.522200   907.074600  1.064700   \n",
       "1983  2977.935423  2373.440416  2171.779115  1151.744525  1.207409   \n",
       "1603  2956.527885  2536.652323  2183.191911   995.962387  1.348479   \n",
       "...           ...          ...          ...          ...       ...   \n",
       "2121  2988.832251  2518.943892  2227.941084  1380.972197  1.548322   \n",
       "1424  3077.470000  2387.730000  2180.888900  1084.722100  0.908500   \n",
       "1725  3090.201242  2524.409307  2195.395247  1345.746906  1.112359   \n",
       "2254  2904.618155  2475.227573  2172.937599   925.868956  1.047679   \n",
       "2915  2983.523282  2489.685582  2169.804637  1293.480283  0.982741   \n",
       "\n",
       "        feature7  feature8  feature9  feature10  feature11  ...  feature581  \\\n",
       "1778  102.077025  0.119660  1.438020   0.005060   0.006540  ...    0.004700   \n",
       "441    95.632200  0.122400  1.472700  -0.000500  -0.007600  ...    0.004700   \n",
       "52    104.521100  0.122100  1.471000   0.044200   0.014600  ...    0.006400   \n",
       "1983  101.097817  0.121995  1.549579   0.013609   0.005740  ...    0.003850   \n",
       "1603  104.080694  0.122884  1.529538  -0.023359  -0.003883  ...    0.007306   \n",
       "...          ...       ...       ...        ...        ...  ...         ...   \n",
       "2121  107.313477  0.122713  1.464299  -0.004470  -0.011010  ...    0.004700   \n",
       "1424   94.246700  0.122600  1.314500   0.041000  -0.020900  ...    0.004700   \n",
       "1725  100.135905  0.123700  1.415041  -0.004198  -0.001794  ...    0.004700   \n",
       "2254  103.826351  0.121855  1.531818  -0.020960   0.003357  ...    0.004765   \n",
       "2915  108.746110  0.124532  1.384817   0.006344  -0.002782  ...    0.004829   \n",
       "\n",
       "      feature582  feature583  feature584  feature585  feature586  feature587  \\\n",
       "1778   72.288900    0.503040    0.010460    0.003190    2.085128    0.026650   \n",
       "441    72.288900    0.500200    0.016200    0.004100    3.246600    0.032900   \n",
       "52     50.871300    0.498700    0.010600    0.003200    2.135600    0.035800   \n",
       "1983   58.474471    0.498650    0.009780    0.002580    1.958154    0.027196   \n",
       "1603  112.416712    0.494457    0.013775    0.003619    2.787776    0.026678   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2121   72.288900    0.501250    0.012642    0.003678    2.523518    0.029922   \n",
       "1424   72.288900    0.497700    0.015100    0.004000    3.033000    0.023200   \n",
       "1725   72.288900    0.501121    0.010838    0.002700    2.161356    0.020761   \n",
       "2254   99.013260    0.502779    0.013103    0.003080    2.602076    0.023556   \n",
       "2915   70.958859    0.498551    0.016340    0.004045    3.283800    0.030427   \n",
       "\n",
       "      feature588  feature589  feature590  \n",
       "1778    0.013950    0.004570   52.572526  \n",
       "441     0.005500    0.002200   16.669500  \n",
       "52      0.018200    0.006400   50.871300  \n",
       "1983    0.013200    0.003610   51.131419  \n",
       "1603    0.020775    0.007306  112.416712  \n",
       "...          ...         ...         ...  \n",
       "2121    0.022965    0.006550   84.970087  \n",
       "1424    0.011900    0.003900   51.472600  \n",
       "1725    0.008666    0.002752   41.905874  \n",
       "2254    0.013508    0.004206   81.909187  \n",
       "2915    0.020020    0.007268   66.090988  \n",
       "\n",
       "[2340 rows x 474 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_dim=474))\n",
    "model.add(Dropout(rate=0.1))\n",
    "model.add(Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compilation - configure the learning process including defining the optimizer, loss function, and metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model  with our training data and by defining the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2340/2340 [==============================] - 1s 423us/step - loss: 15.9288 - acc: 0.5004\n",
      "Epoch 2/5\n",
      "2340/2340 [==============================] - 0s 45us/step - loss: 15.9288 - acc: 0.5004\n",
      "Epoch 3/5\n",
      "2340/2340 [==============================] - 0s 47us/step - loss: 15.9288 - acc: 0.5004\n",
      "Epoch 4/5\n",
      "2340/2340 [==============================] - 0s 44us/step - loss: 15.9288 - acc: 0.5004\n",
      "Epoch 5/5\n",
      "2340/2340 [==============================] - 0s 46us/step - loss: 15.9288 - acc: 0.5004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13edddc50>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply model to test set and evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586/586 [==============================] - 0s 586us/step\n",
      "Test accuracy: 0.4982935157652194\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm_2: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-2f7e154ad2f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m474\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# layer - LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# layer - # of nodes/neurons with relu activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_2: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Embedding layer to convert input to dense vector representations\n",
    "model.add(Dense(32, activation='relu', input_dim=474))\n",
    "# layer - LSTM\n",
    "model.add(LSTM(128))\n",
    "# layer - # of nodes/neurons with relu activation function\n",
    "model.add(Dense(1, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions to Solicit Feedback\n",
    "Write 2-3 questions soliciting feedback on specific aspects on the assignment. For example, if you did something one way but are unsure if there might be a different or better way to do it, ask for feedback on that part. You may submit these questions by commenting out in the code within your .ipynb file or by typing them below your file name in the Your Response box on the Submit Milestone Assignment page. While the questions you submit will have no bearing on your grade, by doing so, you will engage more actively with the assignment and we will also be able to give you pointed feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How can I fix the convegence issue I have with svm.LinearSVC? From what I've found on Stackoverflow, the common response is to increase the iterations. I went from 1000 to 100000; however, still received this error. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. I did not find a difference in performace (accuracy) using thw whole dataset vs. a limited dataset (after dimensionality reduction) when using Decision Tree or Random Forest. Is that normal? If not, how and when should I use dimensionality reduction for these models moving forward? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
