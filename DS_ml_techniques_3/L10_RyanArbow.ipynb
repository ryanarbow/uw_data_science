{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 10 - Assignment\n",
    "\n",
    "Using the Keras dataset, create a new notebook and perform each of the following data preparation tasks and answer the related questions:\n",
    "\n",
    "- Read Reuters dataset into training and testing \n",
    "- Prepare dataset\n",
    "- Build and compile 3 different models using Keras LTSM ideally improving model at each iteration.\n",
    "- Describe and explain your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dropout, Dense, Embedding, LSTM, Bidirectional\n",
    "from keras.datasets import reuters \n",
    "\n",
    "\n",
    "#import numpy and matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset from Keras library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This dataset also makes available the word index used for encoding the sequences:\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30979"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max work length\n",
    "max_words = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue when trying to import dataset. Found help on Stackoverflow with a trick to force reuters.load_data to allow pickle by\n",
    "\n",
    "import numpy as np\n",
    "# save np.load\n",
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(path=\"reuters.npz\",\n",
    "                                                         num_words=max_words,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=113,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)\n",
    "\n",
    "# restore np.load for future normal usage\n",
    "np.load = np_load_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure train and test input vectors have the same dimensionality by padding to a constant length\n",
    "x_train = sequence.pad_sequences(x_train, maxlen = 200) \n",
    "x_test = sequence.pad_sequences(x_test, maxlen = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Embedding layer to convert input to dense vector representations\n",
    "model.add(Embedding(max_words, 256, input_length = 200)) \n",
    "# layer - LSTM\n",
    "model.add(LSTM(128))\n",
    "# layer - # of nodes/neurons with relu activation function\n",
    "model.add(Dense(46, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model  with our training data and by defining the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8982/8982 [==============================] - 57s 6ms/step - loss: 2.0968 - acc: 0.4627\n",
      "Epoch 2/5\n",
      "8982/8982 [==============================] - 56s 6ms/step - loss: 1.6425 - acc: 0.5779\n",
      "Epoch 3/5\n",
      "8982/8982 [==============================] - 55s 6ms/step - loss: 1.4115 - acc: 0.6499\n",
      "Epoch 4/5\n",
      "8982/8982 [==============================] - 56s 6ms/step - loss: 1.1412 - acc: 0.7114\n",
      "Epoch 5/5\n",
      "8982/8982 [==============================] - 58s 6ms/step - loss: 0.9321 - acc: 0.7577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x137509a20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply model to test set and evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 3s 1ms/step\n",
      "Test accuracy: 0.6691896705784547\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build additional models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First model - Add Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "# Embedding layer to convert input to dense vector representations\n",
    "model1.add(Embedding(max_words, 256, input_length = 200)) \n",
    "# LSTM layers\n",
    "model1.add(Bidirectional(LSTM(128)))\n",
    "# layer - # of nodes/neurons with relu activation function\n",
    "model1.add(Dense(46, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8982/8982 [==============================] - 74s 8ms/step - loss: 2.0357 - acc: 0.5002\n",
      "Epoch 2/5\n",
      "8982/8982 [==============================] - 79s 9ms/step - loss: 1.7459 - acc: 0.5620\n",
      "Epoch 3/5\n",
      "8982/8982 [==============================] - 74s 8ms/step - loss: 1.6805 - acc: 0.5827\n",
      "Epoch 4/5\n",
      "8982/8982 [==============================] - 74s 8ms/step - loss: 2.0094 - acc: 0.4546\n",
      "Epoch 5/5\n",
      "8982/8982 [==============================] - 74s 8ms/step - loss: 1.6369 - acc: 0.5916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x147bf7cc0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 3s 1ms/step\n",
      "Test accuracy: 0.5877114870881567\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model1.evaluate(x_test, y_test)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Model - Add dropout to Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "# Embedding layer to convert input to dense vector representations\n",
    "model2.add(Embedding(max_words, 256, input_length = 200)) \n",
    "# LSTM layers\n",
    "model2.add(LSTM(128))\n",
    "# layer - # of nodes/neurons with relu activation function\n",
    "model2.add(Dense(46, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8982/8982 [==============================] - 54s 6ms/step - loss: 2.1030 - acc: 0.4608\n",
      "Epoch 2/10\n",
      "8982/8982 [==============================] - 55s 6ms/step - loss: 1.7077 - acc: 0.5563\n",
      "Epoch 3/10\n",
      "8982/8982 [==============================] - 57s 6ms/step - loss: 1.4511 - acc: 0.6284\n",
      "Epoch 4/10\n",
      "8982/8982 [==============================] - 59s 7ms/step - loss: 1.1712 - acc: 0.6959\n",
      "Epoch 5/10\n",
      "8982/8982 [==============================] - 58s 6ms/step - loss: 0.9934 - acc: 0.7463\n",
      "Epoch 6/10\n",
      "8982/8982 [==============================] - 58s 6ms/step - loss: 0.7626 - acc: 0.8016\n",
      "Epoch 7/10\n",
      "8982/8982 [==============================] - 56s 6ms/step - loss: 0.6075 - acc: 0.8428\n",
      "Epoch 8/10\n",
      "8982/8982 [==============================] - 57s 6ms/step - loss: 0.4715 - acc: 0.8803\n",
      "Epoch 9/10\n",
      "8982/8982 [==============================] - 58s 6ms/step - loss: 0.3772 - acc: 0.9043\n",
      "Epoch 10/10\n",
      "8982/8982 [==============================] - 58s 6ms/step - loss: 0.3191 - acc: 0.9202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14d3e55c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 3s 1ms/step\n",
      "Test accuracy: 0.6812110418521816\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model2.evaluate(x_test, y_test)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most significant increase in accuracy was found when I added epochs to the first LSTM model I created. I attempted a Bidirectional LSTM model; however, acheived lower performance than with standard LSTM.\n",
    "\n",
    "Perhaps further exploration and additional epochs would build upon the Bidirecitonal LSTM and provide further improvements in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
